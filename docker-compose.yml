services:
  web:
    image: ghcr.io/clayauld/pandoc-md2pdf-web:latest
    ports:
      - "8080:8080"
    env_file:
      - server/.env
    restart: unless-stopped
    environment:
      - ENABLE_MEETING_NOTES=false
      - LLM_API_BASE=http://litellm:4000
      - LLM_API_KEY=sk-1234
      - LLM_MODEL=gpt-3.5-turbo
    volumes:
      - ./app-data:/app/server/tmp
      - ./app-data/library:/app/server/data/library

  # Optional LiteLLM service for local LLM integration
  # litellm:
  #   image: ghcr.io/berriai/litellm:main-latest
  #   ports:
  #     - "4000:4000"
  #   environment:
  #     - DATABASE_URL=postgresql://... # If needed
  #     - STORE_MODEL_IN_DB=True
  #     # Add your model providers here (e.g., OPENAI_API_KEY, ANTHROPIC_API_KEY)
  #   command: [ "--port", "4000", "--model", "gpt-3.5-turbo" ]

